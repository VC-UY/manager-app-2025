# ğŸ¯ MANAGER APP - INTERFACE DE GESTION DES WORKFLOWS

---

## ğŸ“ DESCRIPTION DU PROJET

Le **Manager App** est l'application dÃ©diÃ©e aux **gestionnaires de workflows** dans le systÃ¨me de calcul distribuÃ© volontaire. Il permet de crÃ©er, gÃ©rer et superviser les workflows de calcul, d'assigner des tÃ¢ches aux volontaires et de suivre l'exÃ©cution en temps rÃ©el.

**Architecture** : Manager â†” **Coordinator** â†” Volontaire

**RÃ´le** : Interface de gestion des workflows, crÃ©ation de tÃ¢ches, supervision des exÃ©cutions

---

## ğŸ¯ OBJECTIFS

- **Objectif principal** : Fournir une interface complÃ¨te pour la gestion des workflows de calcul distribuÃ©
- **ProblÃ©matique** : Besoin d'un outil simple pour crÃ©er et gÃ©rer des workflows complexes sans expertise technique
- **Solution** : Application Django + Next.js avec authentification, gestion des tÃ¢ches et communication Redis

---

## ğŸ§© FONCTIONNALITÃ‰S

### ğŸ” AUTHENTIFICATION UTILISATEUR
- **Inscription/Connexion** sÃ©curisÃ©e avec tokens
- **Gestion des profils** utilisateur
- **Sessions persistantes** avec Next-Auth
- **Protection des routes** sensibles

### ğŸ“Š GESTION DES WORKFLOWS
- **CrÃ©ation de workflows** avec interface intuitive
- **Configuration des tÃ¢ches** et sous-tÃ¢ches
- **Estimation automatique** des ressources nÃ©cessaires
- **Templates** de workflows prÃ©dÃ©finis

### ğŸ‘¥ SUPERVISION DES VOLONTAIRES
- **Vue d'ensemble** des volontaires connectÃ©s
- **Monitoring** des performances et disponibilitÃ©
- **Attribution intelligente** des tÃ¢ches
- **Historique** des exÃ©cutions

### ğŸ“ˆ TABLEAUX DE BORD
- **Dashboards interactifs** avec graphiques
- **MÃ©triques en temps rÃ©el** des performances
- **Rapports dÃ©taillÃ©s** d'exÃ©cution
- **Alertes** et notifications

### ğŸ”„ COMMUNICATION TEMPS RÃ‰EL
- **WebSockets** pour les mises Ã  jour live
- **IntÃ©gration Redis** pour la communication
- **Notifications push** d'Ã©tat des tÃ¢ches
- **Chat** avec les volontaires (si implÃ©mentÃ©)

---

## ğŸš€ PRÃ‰REQUIS SYSTÃˆME

### ğŸ”§ **Logiciels Requis**
- **Python 3.8+** - [TÃ©lÃ©charger Python](https://www.python.org/downloads/)
- **Node.js 18+** - [TÃ©lÃ©charger Node.js](https://nodejs.org/)

- **Git** - [Installer Git](https://git-scm.com/downloads)

### ğŸŒ **Configuration RÃ©seau**
- **Port 8001** : Backend Django (API REST + WebSockets)
- **Port 3000** : Frontend Next.js (dÃ©veloppement)
- **Coordinateur** : Connexion au Coordinator App sur `COORDINATOR_IP:REDIS_PORT OR COORDINATOR_PROXY_PORT`

---

## ğŸ“¦ INSTALLATION COMPLÃˆTE

### 1ï¸âƒ£ **Cloner le Projet**
```bash
git clone https://github.com/VC-UY/manager-app-2025.git
```

### 2ï¸âƒ£ **Installation Backend (Django)**
```bash
cd manager_backend

# CrÃ©er l'environnement virtuel
python -m venv exp-env

# Activer l'environnement virtuel
# Sur Linux/Mac :
source exp-env/bin/activate
# Sur Windows :
exp-env\Scripts\activate

# Installer les dÃ©pendances Python
pip install -r requirements.txt
```

### 3ï¸âƒ£ **Installation Frontend (Next.js)**
```bash
cd ../manager_frontend

# Installer les dÃ©pendances Node.js
npm install
```

### 4ï¸âƒ£ **Configuration Base de DonnÃ©es**
```bash
cd ../manager_backend

# Activer l'environnement virtuel
source exp-env/bin/activate

# Appliquer les migrations
python manage.py makemigrations
python manage.py migrate

# CrÃ©er un superutilisateur (optionnel)
python manage.py createsuperuser
```


---

## â–¶ï¸ LANCEMENT DE L'APPLICATION

### ğŸš€ **Backend (3 terminaux requis)**

#### **Terminal 1 : Redis Server**
```bash
# DÃ©marrer Redis sur le port par dÃ©faut
redis-server
```

#### **Terminal 2 : Coordinator App** (REQUIS)
```bash
# Se rendre dans le projet Coordinator
cd /path/to/Coordinator-App/coordinator_project

# Activer l'environnement du coordinator
source coordinator-env/bin/activate

# DÃ©marrer le proxy Redis du coordinateur
python manage.py start_redis_proxy --redis-host localhost --redis-port 6379 --proxy-port 6380

# Dans un autre terminal, dÃ©marrer le backend coordinateur
daphne coordinator_project.asgi:application -p 8001 -b 0.0.0.0
```

#### **Terminal 3 : Backend Manager (Django/ASGI)**
```bash
cd manager_backend
source exp-env/bin/activate

# Lancer avec Daphne (ASGI pour WebSockets)
daphne -b 0.0.0.0 -p 8001 websocket_service.asgi:application
```

### ğŸ–¥ï¸ **Frontend**

#### **Terminal 4 : Frontend Next.js**
```bash
cd manager_frontend

# Lancer le serveur de dÃ©veloppement
npm run dev
```

### ğŸŒ **AccÃ©der aux Applications**
- **Frontend Manager** : `http://localhost:3000`
- **Backend API** : `http://localhost:8001/api/`
- **Admin Django** : `http://localhost:8001/admin/`
- **Coordinator** : `http://localhost:5173` (doit Ãªtre dÃ©marrÃ©)

---

## âš™ï¸ CONFIGURATION

### ğŸ”§ **Configuration Backend**
Modifier `manager_backend/manager_backend/settings.py` :

```python
# Base de donnÃ©es SQLite (par dÃ©faut)
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.sqlite3',
        'NAME': BASE_DIR / 'db.sqlite3',
    }
}

# Redis Configuration
REDIS_HOST = 'localhost'
REDIS_PORT = 6379

# Coordinator Configuration
COORDINATOR_HOST = 'localhost'
COORDINATOR_PORT = 6380  # Port du proxy Redis du coordinateur

# CORS pour le frontend
CORS_ALLOWED_ORIGINS = [
    'http://localhost:3000',
    'http://localhost:3001',
]

# Authentification
REST_FRAMEWORK = {
    'DEFAULT_AUTHENTICATION_CLASSES': [
        'rest_framework.authentication.TokenAuthentication',
    ],
}
```

### ğŸŒ **Configuration Frontend**
CrÃ©er `manager_frontend/lib/config.ts` :

```typescript
export const API_BASE_URL = 'http://localhost:8001';
export const COORDINATOR_URL = 'ws://localhost:8001/ws';

// Configuration Next-Auth
export const NEXTAUTH_URL = 'http://localhost:3000';
export const NEXTAUTH_SECRET = 'your-secret-key-here';
```

### ğŸ”’ **Variables d'Environnement**
CrÃ©er `manager_frontend/.env.local` :

```bash
NEXTAUTH_URL=http://localhost:3000
NEXTAUTH_SECRET=your-secret-key-here
API_BASE_URL=http://localhost:8001
```

---

## ğŸ“ STRUCTURE DU PROJET

```
ManagerApp/v2/
â”œâ”€â”€ manager_backend/             # Backend Django
â”‚   â”œâ”€â”€ manage.py               # Point d'entrÃ©e Django
â”‚   â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â”‚   â”œâ”€â”€ db.sqlite3             # Base de donnÃ©es SQLite
â”‚   â”œâ”€â”€ manager_backend/        # Configuration Django
â”‚   â”‚   â”œâ”€â”€ settings.py        # Configuration principale
â”‚   â”‚   â”œâ”€â”€ urls.py            # Routes principales
â”‚   â”‚   â”œâ”€â”€ wsgi.py            # Configuration WSGI
â”‚   â”‚   â””â”€â”€ asgi.py            # Configuration ASGI
â”‚   â”œâ”€â”€ workflows/             # App gestion workflows
â”‚   â”‚   â”œâ”€â”€ models.py          # ModÃ¨les Django
â”‚   â”‚   â”œâ”€â”€ views.py           # API REST workflows
â”‚   â”‚   â”œâ”€â”€ serializers.py     # SÃ©rialiseurs DRF
â”‚   â”‚   â”œâ”€â”€ urls.py            # Routes workflows
â”‚   â”‚   â””â”€â”€ auth.py            # Authentification
â”‚   â”œâ”€â”€ tasks/                 # App gestion tÃ¢ches
â”‚   â”‚   â”œâ”€â”€ models.py          # ModÃ¨les tÃ¢ches
â”‚   â”‚   â”œâ”€â”€ views.py           # API REST tÃ¢ches
â”‚   â”‚   â””â”€â”€ serializers.py     # SÃ©rialiseurs tÃ¢ches
â”‚   â”œâ”€â”€ volunteers/            # App gestion volontaires
â”‚   â”‚   â”œâ”€â”€ models.py          # ModÃ¨les volontaires
â”‚   â”‚   â”œâ”€â”€ views.py           # API REST volontaires
â”‚   â”‚   â””â”€â”€ serializers.py     # SÃ©rialiseurs volontaires
â”‚   â”œâ”€â”€ websocket_service/     # Service WebSockets
â”‚   â”‚   â”œâ”€â”€ asgi.py            # Configuration ASGI
â”‚   â”‚   â”œâ”€â”€ routing.py         # Routes WebSocket
â”‚   â”‚   â””â”€â”€ middleware.py      # Middleware auth
â”‚   â””â”€â”€ redis_communication/   # Communication Redis
â””â”€â”€ manager_frontend/          # Frontend Next.js
    â”œâ”€â”€ package.json           # DÃ©pendances Node.js
    â”œâ”€â”€ next.config.ts         # Configuration Next.js
    â”œâ”€â”€ tailwind.config.js     # Configuration Tailwind
    â”œâ”€â”€ app/                   # App Router Next.js 13+
    â”‚   â”œâ”€â”€ layout.tsx         # Layout principal
    â”‚   â”œâ”€â”€ page.tsx           # Page d'accueil
    â”‚   â”œâ”€â”€ auth/              # Pages authentification
    â”‚   â”œâ”€â”€ dashboard/         # Dashboard principal
    â”‚   â”œâ”€â”€ workflows/         # Gestion workflows
    â”‚   â””â”€â”€ volunteers/        # Gestion volontaires
    â”œâ”€â”€ components/            # Composants React
    â”‚   â”œâ”€â”€ ui/                # Composants UI rÃ©utilisables
    â”‚   â”œâ”€â”€ forms/             # Formulaires
    â”‚   â””â”€â”€ charts/            # Graphiques
    â”œâ”€â”€ lib/                   # Utilitaires
    â”‚   â”œâ”€â”€ api.ts             # Client API
    â”‚   â””â”€â”€ auth.ts            # Configuration auth
    â””â”€â”€ public/                # Assets statiques
```

---

## ğŸ”„ FONCTIONNEMENT

### 1. **DÃ©marrage du Manager**
- Redis dÃ©marre pour la communication
- Le Coordinator App doit Ãªtre en cours d'exÃ©cution
- Le backend Django/ASGI dÃ©marre avec WebSockets
- Le frontend Next.js se connecte au backend

### 2. **Authentification Manager**
- Manager s'inscrit/se connecte via l'interface Next.js
- Token d'authentification stockÃ© cÃ´tÃ© client
- Communication sÃ©curisÃ©e avec le Coordinator

### 3. **CrÃ©ation de Workflows**
- Interface intuitive pour dÃ©finir les workflows
- Configuration des tÃ¢ches et sous-tÃ¢ches
- Estimation automatique des ressources
- Validation avant soumission

### 4. **Attribution des TÃ¢ches**
- Le workflow est soumis au Coordinator
- Le Coordinator distribue aux volontaires disponibles
- Suivi en temps rÃ©el via WebSockets
- Notifications de progression

### 5. **Supervision**
- Dashboard temps rÃ©el des exÃ©cutions
- MÃ©triques de performance
- Gestion des erreurs et reprises
- Rapports dÃ©taillÃ©s

---

## ğŸ›‘ ARRÃŠTER L'APPLICATION

```bash
# Dans chaque terminal, appuyez sur :
Ctrl + C

# ArrÃªter Redis
redis-cli shutdown

# DÃ©sactiver l'environnement virtuel
deactivate
```

---

## ğŸ› DÃ‰PANNAGE

### âŒ **Erreur de connexion au Coordinator**
```bash
# VÃ©rifier que le Coordinator est dÃ©marrÃ©
curl http://localhost:8001/api/system-health/

# VÃ©rifier le proxy Redis du coordinateur
telnet localhost 6380
```

### âŒ **Erreur de connexion Redis**
```bash
# VÃ©rifier que Redis fonctionne
redis-cli ping

# RedÃ©marrer Redis si nÃ©cessaire
sudo systemctl restart redis-server
```

### âŒ **Erreur de migration Django**
```bash
cd manager_backend
source exp-env/bin/activate

# RÃ©initialiser les migrations si nÃ©cessaire
python manage.py migrate --run-syncdb
```

### âŒ **Erreur de build Next.js**
```bash
cd manager_frontend

# Nettoyer le cache
rm -rf .next node_modules
npm install
npm run dev
```

### âŒ **ProblÃ¨me d'authentification**
VÃ©rifier les variables d'environnement :
```bash
# manager_frontend/.env.local
NEXTAUTH_URL=http://localhost:3000
NEXTAUTH_SECRET=your-secret-key-here
```

---

## ğŸ“Š MONITORING

### ğŸ“ˆ **Tableau de Bord**
- **URL** : `http://localhost:3000/dashboard`
- **FonctionnalitÃ©s** :
  - Vue d'ensemble des workflows
  - Status des volontaires
  - Performances en temps rÃ©el
  - Historique des exÃ©cutions

### ğŸ“‹ **API de Surveillance**
```bash
# Status des workflows
curl http://localhost:8001/api/workflows/

# Volontaires disponibles
curl http://localhost:8001/api/volunteers/

# TÃ¢ches en cours
curl http://localhost:8001/api/tasks/
```

### ğŸ” **Logs et Debug**
```bash
# Logs du backend Django
tail -f manager_backend/server.log

# Logs Next.js (dans le terminal)
# Les erreurs s'affichent directement

# Debug API avec headers
curl -H "Authorization: Token YOUR_TOKEN" http://localhost:8001/api/workflows/
```

---

## ğŸ”§ COMMANDES UTILES

### ğŸ“Š **Gestion Django**
```bash
cd manager_backend
source exp-env/bin/activate

# CrÃ©er des migrations
python manage.py makemigrations

# Appliquer les migrations
python manage.py migrate

# Shell Django
python manage.py shell

# CrÃ©er un superutilisateur
python manage.py createsuperuser
```

### ğŸ“¡ **Gestion Next.js**
```bash
cd manager_frontend

# Build de production
npm run build

# DÃ©marrer en production
npm start

# Linter le code
npm run lint
```

### ğŸ› **Debug**
```bash
# Test de l'API backend
curl -X POST http://localhost:8001/api/workflows/auth/login/ \
  -H "Content-Type: application/json" \
  -d '{"email":"test@example.com","password":"testpass"}'

# Test WebSocket
# Utiliser un client WebSocket pour tester ws://localhost:8001/ws/
```

---

## ğŸš€ PRODUCTION

### ğŸ”§ **DÃ©ploiement Backend**
```bash
# Variables d'environnement production
export DJANGO_SETTINGS_MODULE=manager_backend.settings_prod
export DEBUG=False

# Collecter les fichiers statiques
python manage.py collectstatic

# Utiliser Gunicorn avec Workers ASGI
gunicorn manager_backend.asgi:application -k uvicorn.workers.UvicornWorker
```

### ğŸŒ **DÃ©ploiement Frontend**
```bash
# Build de production
npm run build

# Variables d'environnement
export NODE_ENV=production
export NEXTAUTH_URL=https://yourdomain.com

# DÃ©marrer
npm start
```

---

## ğŸ“„ LICENCE

Ce projet est **open source** sous licence MIT.  
RÃ©utilisation, modification et contribution autorisÃ©es.

---

## ğŸ‘¥ CONTRIBUTEURS

- **Ã‰quipe Manager** - DÃ©veloppement de l'interface de gestion
- **Ã‰quipe Coordinator** - IntÃ©gration systÃ¨me
- **Ã‰quipe Frontend** - Interface utilisateur Next.js

---

## ğŸ“ SUPPORT

En cas de problÃ¨me :

1. **VÃ©rifier les prÃ©requis** : Python, Node.js, Redis
2. **S'assurer que le Coordinator fonctionne** : Port 8001 et 6380
3. **Consulter les logs** : `server.log`, terminal Next.js
4. **Tester les connexions** : Redis (6379), Backend (8001), Frontend (3000)
5. **Contacter l'Ã©quipe via [mail](mailto:sergenoah91@gmail.com)** :  si le problÃ¨me persiste

### ğŸ”— **Liens Utiles**
- Documentation Django : https://docs.djangoproject.com/
- Documentation Next.js : https://nextjs.org/docs
- Documentation React : https://reactjs.org/docs/
- Documentation Tailwind CSS : https://tailwindcss.com/docs

---

## ğŸ› ï¸ CRÃ‰ATION DE WORKFLOWS PERSONNALISÃ‰S

### ğŸ“‹ **Vue d'ensemble**

L'application Manager permet d'ajouter facilement de nouveaux types de workflows personnalisÃ©s. Actuellement, deux types sont implÃ©mentÃ©s comme exemples :
- **ML_TRAINING** : EntraÃ®nement de modÃ¨les de machine learning (CIFAR-100)
- **OPEN_MALARIA** : Simulations Ã©pidÃ©miologiques OpenMalaria

**âš ï¸ Note importante** : Les dÃ©pendances entre tÃ¢ches sont prises en compte dans les modÃ¨les mais n'ont pas encore Ã©tÃ© testÃ©es dans l'assignation des tÃ¢ches.

### ğŸ”§ **Ã‰tapes pour crÃ©er un workflow personnalisÃ©**

#### **1. Ajouter le type de workflow**

Modifier `manager_backend/workflows/models.py` :

```python
class WorkflowType(models.TextChoices):
    MATRIX_ADDITION = 'MATRIX_ADDITION', 'Addition de matrices de grande taille'
    MATRIX_MULTIPLICATION = 'MATRIX_MULTIPLICATION', 'Multiplication de matrices de grande taille'
    ML_TRAINING = 'ML_TRAINING', 'EntraÃ®nement de modÃ¨le machine learning'
    OPEN_MALARIA = 'OPEN_MALARIA', 'Simulation OpenMalaria'
    # â• Ajouter votre nouveau type ici
    YOUR_CUSTOM_TYPE = 'YOUR_CUSTOM_TYPE', 'Description de votre workflow'
```

#### **2. CrÃ©er la fonction de dÃ©coupage**

Ajouter votre fonction dans `manager_backend/workflows/split_workflow.py` :

```python
def split_your_custom_workflow(workflow_instance: Workflow, logger: logging.Logger, **kwargs):
    """
    DÃ©coupe votre workflow personnalisÃ© en tÃ¢ches plus petites.
    
    Args:
        workflow_instance (Workflow): Instance du workflow Ã  dÃ©couper
        logger (logging.Logger): Logger pour les messages
        **kwargs: ParamÃ¨tres spÃ©cifiques Ã  votre workflow
    
    Returns:
        list: Liste des tÃ¢ches crÃ©Ã©es
    """
    input_dir = os.path.join(workflow_instance.executable_path, "inputs")
    min_resources = get_min_volunteer_resources()
    
    # Configuration de l'image Docker pour vos tÃ¢ches
    docker_img = {
        "name": "your-custom-image",
        "tag": "latest"
    }
    
    tasks = []
    
    # Exemple : crÃ©er plusieurs tÃ¢ches basÃ©es sur vos donnÃ©es
    for i in range(kwargs.get('num_tasks', 4)):
        # PrÃ©parer les donnÃ©es d'entrÃ©e pour cette tÃ¢che
        # Exemple : gÃ©nÃ©rer des fichiers de configuration, dÃ©couper des datasets, etc.
        
        # Calculer la taille des donnÃ©es d'entrÃ©e
        input_size = 100  # Remplacer par le calcul rÃ©el
        
        # CrÃ©er la tÃ¢che
        task = Task.objects.create(
            workflow=workflow_instance,
            name=f"Custom Task {i}",
            description=f"Description de la tÃ¢che {i}",
            command="your_command_here",  # Commande Ã  exÃ©cuter dans le conteneur
            parameters=[],  # ParamÃ¨tres additionnels si nÃ©cessaire
            input_files=[f"task_{i}/input.dat"],  # Fichiers d'entrÃ©e
            output_files=[f"task_{i}/output.dat"],  # Fichiers de sortie attendus
            status=TaskStatus.CREATED,
            parent_task=None,  # Pour les dÃ©pendances entre tÃ¢ches
            is_subtask=False,
            progress=0,
            start_time=None,
            docker_info=docker_img,
            required_resources={
                "cpu": min_resources["min_cpu"],
                "ram": min_resources["min_ram"],
                "disk": min_resources["disk"],
            },
            estimated_max_time=300,  # Temps estimÃ© en secondes
        )
        task.input_size = input_size
        task.save()
        tasks.append(task)
        logger.warning(f"TÃ¢che {i}: {task} crÃ©Ã©e avec succÃ¨s")
    
    workflow_instance.tasks.add(*tasks)
    workflow_instance.save()
    return tasks
```

#### **3. IntÃ©grer dans la fonction principale**

Modifier la fonction `split_workflow` dans le mÃªme fichier :

```python
def split_workflow(id: uuid.UUID, workflow_type: WorkflowType, logger, **kwargs):
    """
    DÃ©coupe un workflow en tÃ¢ches plus petites selon le type de workflow.
    """
    workflow_instance = Workflow.objects.get(id=id)
    
    if workflow_type == WorkflowType.ML_TRAINING:
        tasks = split_ml_training_workflow(workflow_instance, logger)
    elif workflow_type == WorkflowType.OPEN_MALARIA:
        num_tasks = kwargs.get('num_tasks')
        population_per_task = kwargs.get('population_per_task')
        if num_tasks is None or population_per_task is None:
            raise ValueError("num_tasks et population_per_task doivent Ãªtre spÃ©cifiÃ©s pour OpenMalaria")
        tasks = split_openmalaria_workflow(workflow_instance, num_tasks, population_per_task, logger)
    # â• Ajouter votre workflow ici
    elif workflow_type == WorkflowType.YOUR_CUSTOM_TYPE:
        tasks = split_your_custom_workflow(workflow_instance, logger, **kwargs)
    else:
        raise ValueError(f"Type de workflow non supportÃ©: {workflow_type}")
    
    return tasks
```

#### **4. CrÃ©er la vue de soumission**

CrÃ©er `manager_backend/workflows/your_custom_views.py` :

```python
from rest_framework.decorators import api_view
from django.http import JsonResponse
from django.shortcuts import get_object_or_404
from django.utils import timezone
import logging
import threading
import traceback
from workflows.models import Workflow, WorkflowStatus, WorkflowType
from websocket_service.client import notify_event

logger = logging.getLogger(__name__)

@api_view(['POST'])
def submit_your_custom_workflow_view(request, workflow_id):
    """
    Soumet un workflow personnalisÃ© pour traitement.
    
    Args:
        workflow_id (str): ID du workflow
        request.data: ParamÃ¨tres spÃ©cifiques Ã  votre workflow
    
    Returns:
        JsonResponse: Statut de la soumission
    """
    try:
        # RÃ©cupÃ©rer et valider les paramÃ¨tres
        custom_param1 = request.data.get('custom_param1')
        custom_param2 = request.data.get('custom_param2')
        
        # Validation des paramÃ¨tres
        if not custom_param1:
            return JsonResponse({
                'error': 'custom_param1 est requis'
            }, status=400)
        
        # RÃ©cupÃ©rer le workflow
        workflow = get_object_or_404(Workflow, id=workflow_id)
        if workflow.workflow_type != WorkflowType.YOUR_CUSTOM_TYPE:
            return JsonResponse({
                'error': 'Le workflow doit Ãªtre de type YOUR_CUSTOM_TYPE'
            }, status=400)
        
        # Notifier le dÃ©but
        notify_event('workflow_status_change', {
            'workflow_id': str(workflow_id),
            'status': 'SUBMITTING',
            'message': 'Soumission du workflow personnalisÃ© en cours...'
        })
        
        # VÃ©rifier les volontaires disponibles
        from workflows.handlers import submit_workflow_handler
        success, response = submit_workflow_handler(str(workflow_id))
        
        if not success:
            notify_event('workflow_status_change', {
                'workflow_id': str(workflow_id),
                'status': 'SUBMISSION_FAILED',
                'message': f"Ã‰chec de la soumission: {response.get('message', 'Erreur inconnue')}"
            })
            return JsonResponse({'success': False, 'response': response}, status=400)
        
        # Mettre Ã  jour le statut
        workflow.status = WorkflowStatus.SPLITTING
        workflow.submitted_at = timezone.now()
        workflow.save()
        
        # Lancer le traitement asynchrone
        def process_workflow_async():
            thread_logger = logging.getLogger(f"workflow_thread_{workflow_id}")
            
            try:
                # DÃ©marrer le serveur de fichiers
                from tasks.file_server import start_file_server
                server_port = start_file_server(workflow)
                
                # DÃ©couper le workflow
                from workflows.split_workflow import split_workflow
                tasks = split_workflow(
                    workflow.id, 
                    WorkflowType.YOUR_CUSTOM_TYPE, 
                    thread_logger,
                    custom_param1=custom_param1,
                    custom_param2=custom_param2
                )
                
                thread_logger.info(f"DÃ©coupage terminÃ©, {len(tasks)} tÃ¢ches crÃ©Ã©es")
                
                # Attribution des tÃ¢ches (logique similaire Ã  openmalaria_views.py)
                if response.get('volunteers'):
                    from tasks.scheduller import assign_workflow_to_volunteers
                    assignment_result = assign_workflow_to_volunteers(workflow, response.get('volunteers'))
                    
                    # Publier les assignations aux volontaires
                    # ... (logique de publication Redis)
                    
                notify_event('workflow_status_change', {
                    'workflow_id': str(workflow_id),
                    'status': workflow.status,
                    'message': 'Processus de soumission terminÃ©'
                })
                
            except Exception as e:
                thread_logger.error(f"Erreur lors du traitement: {e}")
                workflow.status = WorkflowStatus.FAILED
                workflow.save()
        
        # DÃ©marrer le thread
        thread = threading.Thread(target=process_workflow_async)
        thread.daemon = True
        thread.start()
        
        return JsonResponse({
            'success': True, 
            'message': 'Workflow personnalisÃ© soumis, traitement en cours'
        }, status=200)
        
    except Exception as e:
        logger.error(f"Erreur inattendue: {e}")
        return JsonResponse({'error': f'Erreur inattendue: {str(e)}'}, status=500)
```

#### **5. Ajouter les routes**

Modifier `manager_backend/workflows/urls.py` :

```python
from django.urls import path
from . import views, openmalaria_views, your_custom_views

urlpatterns = [
    # ... routes existantes ...
    
    # â• Ajouter votre route
    path('submit_your_custom/<uuid:workflow_id>/', 
         your_custom_views.submit_your_custom_workflow_view, 
         name='submit_your_custom_workflow'),
]
```

#### **6. Ajouter l'estimation des ressources**

Modifier `manager_backend/workflows/handlers.py` :

```python
def submit_workflow_handler(workflow_id: str, callback: Optional[Callable[[Dict[str, Any]], None]] = None, timeout: int = 60):
    # ... code existant ...
    
    # Estimer les ressources
    estimated_resources = None
    if workflow.workflow_type == WorkflowType.ML_TRAINING:
        estimated_resources = estimate_ml_training_resources(workflow.input_data_size)
    elif workflow.workflow_type == WorkflowType.OPEN_MALARIA:
        estimated_resources = estimate_open_malaria_resources(workflow.metadata.get('num_task', 4))
    # â• Ajouter votre estimation
    elif workflow.workflow_type == WorkflowType.YOUR_CUSTOM_TYPE:
        estimated_resources = estimate_your_custom_resources(workflow.metadata)
    # ... reste du code ...
```

#### **7. Mettre Ã  jour le frontend**

Ajouter votre type dans `manager_frontend/app/workflows/create/page.tsx` :

```typescript
const workflowTypes = [
  { value: 'MATRIX_ADDITION', label: 'Addition de matrices' },
  { value: 'MATRIX_MULTIPLICATION', label: 'Multiplication de matrices' },
  { value: 'ML_TRAINING', label: 'EntraÃ®nement ML' },
  { value: 'OPEN_MALARIA', label: 'Simulation OpenMalaria' },
  // â• Ajouter votre type
  { value: 'YOUR_CUSTOM_TYPE', label: 'Votre workflow personnalisÃ©' },
];
```

### ğŸ³ **PrÃ©paration du conteneur Docker**

Votre workflow aura besoin d'une image Docker qui devra Ãªtre disponible chez chacun des volontaires ou sur le docker hub. CrÃ©er un `Dockerfile` :

```dockerfile
FROM python:3.9-slim

# Installer les dÃ©pendances de votre application
RUN apt-get update && apt-get install -y \
    your-dependencies \
    && rm -rf /var/lib/apt/lists/*

# Copier votre code
COPY your_app/ /app/
WORKDIR /app

# Installer les dÃ©pendances Python
COPY requirements.txt .
RUN pip install -r requirements.txt

# Point d'entrÃ©e
ENTRYPOINT ["python", "your_main_script.py"]
```

### ğŸ“ **Structure des fichiers**

Organiser vos fichiers comme suit :

```
workflows/examples/your_custom/
â”œâ”€â”€ inputs/                 # Dossier pour les donnÃ©es d'entrÃ©e gÃ©nÃ©rÃ©es
â”‚   â”œâ”€â”€ task_0/
â”‚   â”‚   â””â”€â”€ input.dat
â”‚   â”œâ”€â”€ task_1/
â”‚   â”‚   â””â”€â”€ input.dat
â”‚   â””â”€â”€ ...
â”œâ”€â”€ outputs/               # Dossier pour les rÃ©sultats
â”‚   â”œâ”€â”€ task_0/
â”‚   â”‚   â””â”€â”€ output.dat
â”‚   â””â”€â”€ ...
â”œâ”€â”€ scripts/               # Scripts utilitaires
â”‚   â”œâ”€â”€ prepare_data.py
â”‚   â””â”€â”€ process_results.py
â””â”€â”€ docker/               # Configuration Docker
    â”œâ”€â”€ Dockerfile
    â””â”€â”€ requirements.txt
```

### ğŸ”— **Gestion des dÃ©pendances entre tÃ¢ches**

Pour crÃ©er des tÃ¢ches avec dÃ©pendances :

```python
# CrÃ©er la tÃ¢che parent
parent_task = Task.objects.create(
    workflow=workflow_instance,
    name="TÃ¢che initiale",
    # ... autres paramÃ¨tres ...
)

# CrÃ©er une tÃ¢che dÃ©pendante
dependent_task = Task.objects.create(
    workflow=workflow_instance,
    name="TÃ¢che dÃ©pendante",
    parent_task=parent_task,  # â† DÃ©finir la dÃ©pendance
    is_subtask=True,
    # ... autres paramÃ¨tres ...
)
```

### ğŸ“Š **Estimation des ressources**

ImplÃ©menter une fonction d'estimation :

```python
def estimate_your_custom_resources(metadata):
    """
    Estime les ressources nÃ©cessaires pour votre workflow.
    
    Args:
        metadata (dict): MÃ©tadonnÃ©es du workflow
    
    Returns:
        dict: Ressources estimÃ©es
    """
    base_cpu = 2
    base_ram = 1024  # MB
    base_disk = 2048  # MB
    
    # Adapter selon vos paramÃ¨tres
    num_tasks = metadata.get('num_tasks', 4)
    data_size = metadata.get('data_size', 100)
    
    return {
        "cpu": base_cpu,
        "ram": base_ram + (data_size * 10),
        "disk": base_disk + (data_size * 20),
        "estimated_time": num_tasks * 300,  # secondes
    }
```

### ğŸ§ª **Test de votre workflow**

1. **CrÃ©er un workflow de test** via l'interface
2. **Soumettre avec des paramÃ¨tres simples**
3. **VÃ©rifier les logs** dans les terminaux
4. **Valider la gÃ©nÃ©ration des tÃ¢ches**
5. **Tester l'assignation** aux volontaires

### ğŸ“ **Exemple complet : Workflow de traitement d'images**

Voici un exemple concret pour un workflow de traitement d'images :

```python
def split_image_processing_workflow(workflow_instance: Workflow, logger: logging.Logger, **kwargs):
    """DÃ©coupe un workflow de traitement d'images en tÃ¢ches."""
    
    input_dir = os.path.join(workflow_instance.executable_path, "inputs")
    image_folder = kwargs.get('image_folder', '/path/to/images')
    filter_type = kwargs.get('filter_type', 'blur')
    
    # Lister les images Ã  traiter
    import os
    image_files = [f for f in os.listdir(image_folder) 
                   if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    
    # Grouper les images par batch
    batch_size = kwargs.get('batch_size', 10)
    batches = [image_files[i:i+batch_size] 
               for i in range(0, len(image_files), batch_size)]
    
    tasks = []
    for i, batch in enumerate(batches):
        # CrÃ©er le dossier d'entrÃ©e pour ce batch
        batch_dir = os.path.join(input_dir, f"batch_{i}")
        os.makedirs(batch_dir, exist_ok=True)
        
        # CrÃ©er un fichier de configuration
        config = {
            'images': batch,
            'filter_type': filter_type,
            'output_format': 'png'
        }
        
        import json
        with open(os.path.join(batch_dir, 'config.json'), 'w') as f:
            json.dump(config, f)
        
        # CrÃ©er la tÃ¢che
        task = Task.objects.create(
            workflow=workflow_instance,
            name=f"Image Processing Batch {i}",
            description=f"Traitement de {len(batch)} images avec filtre {filter_type}",
            command=f"python process_images.py --config /input/config.json --output /output/",
            parameters=[],
            input_files=[f"batch_{i}/config.json"],
            output_files=[f"batch_{i}/processed/"],
            status=TaskStatus.CREATED,
            docker_info={
                "name": "image-processor",
                "tag": "latest"
            },
            required_resources={
                "cpu": 2,
                "ram": 2048,
                "disk": len(batch) * 50,  # 50MB par image
            },
            estimated_max_time=len(batch) * 30,  # 30s par image
        )
        
        tasks.append(task)
    
    workflow_instance.tasks.add(*tasks)
    workflow_instance.save()
    return tasks
```

Cette architecture modulaire permet d'ajouter facilement de nouveaux types de workflows tout en maintenant la compatibilitÃ© avec l'infrastructure existante.

---